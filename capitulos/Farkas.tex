\chapter{Lema de Farkas}

En la sección anterior hemos vimos como uno de los teoremas de separación implica el único teorema de la alternativa que hemos visto hasta el momento. Ahora, vamos a deducir de manera parecida otro teorema de la alternativa. Antes exponemos la siguiente definición.

\begin{definicion}
	Dados $ \{x_1,\dots, x_M \} \subset \RR^N  $ con $ M, N \in \NN $, llamamos cono generado por $ \{x_1,\dots, x_M \} $ al conjunto convexo y cerrado de $ \RR^N $ dado por:
	\begin{equation*}
	\mathrm{cone}\{x_1,\dots, x_M \} := \left\lbrace \sum_{j=1}^{N}{\mu_j x_j } : \text{ } \mu_1,...,\mu_N \geq 0 \right\rbrace .
	\end{equation*}
\end{definicion}

Veamos que efectivamente $ \mathrm{cone}\{x_1,\dots, x_M \} $ es convexo y compacto:

\begin{itemize}
	\item  Convexo: tenemos que comprobar que dados $ \ttt, \sss \in \mathrm{cone}\{x_1,\dots, x_M \} $ y $ \lambda \in \lbrack 0,1 \rbrack $ entonces $ \lambda\ttt + (1-\lambda)\sss \in \mathrm{cone}\{x_1,\dots, x_M \} $. En efecto:

	\begin{equation*}
	\begin{split}
		\lambda\ttt + (1-\lambda)\sss &=   \lambda \sum_{j=1}^{N}{\mu_j^t x_j } + (1-\lambda)\sum_{j=1}^{N}{\mu_j^s x_j } \\
		&= \sum_{j=1}^{N}{\lbrack \lambda \mu_j^t x_j  + (1-\lambda)\mu_j^s x_j \rbrack} \\
		&= \sum_{j=1}^{N}{\lbrack \lambda \mu_j^t  + (1-\lambda)\mu_j^s \rbrack x_j}.
		\end{split}
		\end{equation*}
Como $ \mu_j^t \text{ y } \mu_j^s $ son no negativos, entonces $ \lambda \mu_j^t  + (1-\lambda)\mu_j^s  $ también es una cantidad no negativa para $ j=1,\dots,M $. Así, podemos concluir que $ \lambda\ttt + (1-\lambda)\sss \in \mathrm{cone}\{x_1,\dots, x_M \} $ y por tanto es un subconjunto convexo.

\item Cerrado: sea $ \lbrace \ttt_n \rbrace_{ n \in \NN} $ una sucesión de $ \mathrm{cone}\{x_1,\dots, x_M \} $ y sea $ \ttt_0 \in \RR^N $ tal que $ \lbrace \ttt_n \rbrace_{ n \in \NN} \longrightarrow \ttt_0 $. Si notamos $ \ttt_n = \sum_{j=1}^{N}{\mu_j^n x_j }$, entonces:
\[
\lbrace \ttt_n \rbrace_{ n \in \NN} = \lbrace \sum_{j=1}^{N}{\mu_j^n x_j } \rbrace_{ n \in \NN} \longrightarrow \sum_{j=1}^{N}{\mu_j^0 x_j } = \ttt_0.
\]
Como para cada $ \ttt_n $ para $ n \in \NN $ cumple que $ \mu_j^n \geq 0$ con $ j=1,\dots,N $ podemos asegurar que $ \mu_j^0 \geq $ con $ j=1,\dots,N $. Hemos demostrado que $ \ttt_0 $ se expresa como combinación de $ \{x_1,\dots, x_M \} $ con coeficientes no negativos. Por lo tanto, $ \ttt_0 \in \mathrm{cone}\{x_1,\dots, x_M \}  $ y por consiguiente es cerrado. 
\end{itemize} 

Enunciamos ahora otro de los teoremas de la alternativa más conocidos.

\begin{lemaBox}[Lema de Farkas]
Sean $ \{x_1,\dots, x_M \} \subset \RR^N $ y $ b \in \RR^N $ con $ M,N \in \RR^N $. Entonces una, y solo una, de la siguientes afirmaciones se cumple:
\begin{itemize}
\item[i')] $ \exists \mu_1,\dots,\mu_M \geq 0 $ tal que $ b = \sum_{j=1}^{M} \mu_j x_j$.
\item[ii')]$ \exists z_0 \in \RR^N $ que cumple que:
\begin{enumerate}
	\item $ \max_{ j=1,\dots,M} \langle z_0, x_j \rangle \leq 0$ y
	\item $ \langle z_0, b\rangle > 0$.
\end{enumerate} 
\end{itemize}
\end{lemaBox}

\begin{proof}
Planteamos las siguientes alternativas, que obviamente son excluyentes excluyentes, y que implican las de la tesis del lema:
\begin{itemize}
	\item[a)] $b \in \mathrm{cone}\{x_1,\dots, x_M \} $. Estamos en el caso $ i') $  ya que:
	\[
	b \in \left\lbrace \sum_{j=1}^{N}{\mu_j x_j } : \text{ } \mu_1,...,\mu_N \geq 0 \right\rbrace .
	\]
	\item[b)] $ b \notin \mathrm{cone}\{x_1,\dots, x_M \} $. Por su parte, esta alternativa implica $ ii') $. En efecto: 
	
	\begin{itemize}
	\item[$ ii') \Longrightarrow b) $] Razonamos por contradicción. Suponemos que $ b \in \mathrm{cone}\{x_1,\dots, x_M \} $, entonces, podemos expresar $ b =  \sum_{j=1}^{N}{\mu_j x_j } $ con $ \mu_1,...,\mu_N \geq 0$. Como se da $ ii') $, en particular se cumple 1 y obtenemos
	\begin{equation*}
	\begin{split}
		\langle z_0, b \rangle & = \langle z_0, \sum_{j=1}^{N}{\mu_j x_j } \rangle \\
		&= \sum_{j=1}^{N}{\mu_j\langle z_0, x_j \rangle } \leq 0.
	\end{split}
	\end{equation*}
	
	Por otro lado, por 2 se tiene que  $ \langle z_0, b\rangle > 0$. Así, obtenemos que
	\[
	\langle z_0, b \rangle \leq 0 <  \langle z_0, b \rangle,
	\]
	lo cual es imposible.
	\item[$ b) \Longrightarrow ii') $] Si $ b \notin \mathrm{cone}\{x_1,\dots, x_M \} $ aplicamos el teorema de separación (\ref{separacion1}) a los conjuntos $ \{b\} $ que es compacto y convexo y a $ \mathrm{cone}\{x_1,\dots, x_M \} $ que es cerrado y convexo. Obtenemos que:
	\[
	\exists z_0 \in \RR^N: \text{ } \sup_{a \in \mathrm{cone}\{x_1,\dots, x_M \}} \langle z_0, a \rangle < \langle z_0, b \rangle.
	\]
	Por un lado, es obvio que $ 0 \in \mathrm{cone}\{x_1,\dots, x_M \} $ y por ello:
	\[
	0 = \langle z_0, 0\rangle \leq \sup_{a \in \mathrm{cone}\{x_1,\dots, x_M \}} \langle z_0, a \rangle < \langle z_0, b \rangle.
	\]
	Hemos obtenido por tanto que es cierto $ 2 $. Para probar $ 1 $, fijamos $ a_0 \in \mathrm{co}\{x_1,\dots, x_M \}$ (es obvio si $ \mathrm{co}\{x_1,\dots, x_M \} = \{0\}$). Entonces, dado $ \rho > 0 $,
	\[
	\rho\langle z_0, a_0 \rangle = \langle z_0, \rho a_0 \rangle \leq \sup_{a \in \mathrm{cone}\{x_1,\dots, x_M \}} \langle z_0, a_0 \rangle.
	\]
	Llegamos a que el conjunto $ \lbrace\rho\langle z_0, a_0 \rangle: \text{ } \rho > 0 \rbrace  $ está acotado y eso solo es posible si $ \langle z_0, a_0 \rangle \leq 0 $. La arbitrariedad de $ a_0 $ nos aporta que \[ \sup_{a \in \mathrm{cone}\{x_1,\dots, x_M \}} = 0 \] de donde \[
	\max_{ j=1,\dots,M} \langle z_0, x_j \rangle \leq \sup_{a \in \mathrm{cone}\{x_1,\dots, x_M \}} = 0  
	\]
	y, en particular, hemos probado 1.
	\end{itemize}
\end{itemize}
\end{proof}